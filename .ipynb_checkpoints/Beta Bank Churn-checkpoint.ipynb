{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Bank Churn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to investigate the churn of Beta Bank customers. The bank has noticed customers are slowly leaving, month over month. The most cost effective solution is to retain existing customers, rather than recruit new customers. The bank needs a model that will predict whether a customer will leave the bank soon. The model will be trained on data from clients' past behavior and termination of contracts with the bank. The goal of the project is to build a model with an F1 score of at least 0.59.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary classification problem, therefore, we will be focussing on that class of modeling. This is the case because the target is categorical: churn or not. The F1 score is an appropriate indicator of our model, because we care about both precision and recall. We care about precision because we want to capture as many true positive occurrences of churning. Recall is also crucial, as we want to capture as many occurrences of churning as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd \n",
    "import plotly_express as px\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error as mse, f1_score, accuracy_score, recall_score, precision_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv('datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall description of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.007322</td>\n",
       "      <td>-0.009067</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>-0.005988</td>\n",
       "      <td>-0.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>0.004202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.006248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.027094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013134</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.285323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>-0.007322</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.013134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>-0.032178</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>-0.016761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>-0.009067</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.118533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.047820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.007138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.032178</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>-0.156128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>-0.005988</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>-0.016571</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>-0.027094</td>\n",
       "      <td>0.285323</td>\n",
       "      <td>-0.016761</td>\n",
       "      <td>0.118533</td>\n",
       "      <td>-0.047820</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>-0.156128</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RowNumber  CustomerId  CreditScore       Age    Tenure  \\\n",
       "RowNumber         1.000000    0.004202     0.005840  0.000783 -0.007322   \n",
       "CustomerId        0.004202    1.000000     0.005308  0.009497 -0.021418   \n",
       "CreditScore       0.005840    0.005308     1.000000 -0.003965 -0.000062   \n",
       "Age               0.000783    0.009497    -0.003965  1.000000 -0.013134   \n",
       "Tenure           -0.007322   -0.021418    -0.000062 -0.013134  1.000000   \n",
       "Balance          -0.009067   -0.012419     0.006268  0.028308 -0.007911   \n",
       "NumOfProducts     0.007246    0.016972     0.012238 -0.030680  0.011979   \n",
       "HasCrCard         0.000599   -0.014025    -0.005458 -0.011721  0.027232   \n",
       "IsActiveMember    0.012044    0.001665     0.025651  0.085472 -0.032178   \n",
       "EstimatedSalary  -0.005988    0.015271    -0.001384 -0.007201  0.010520   \n",
       "Exited           -0.016571   -0.006248    -0.027094  0.285323 -0.016761   \n",
       "\n",
       "                  Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber       -0.009067       0.007246   0.000599        0.012044   \n",
       "CustomerId      -0.012419       0.016972  -0.014025        0.001665   \n",
       "CreditScore      0.006268       0.012238  -0.005458        0.025651   \n",
       "Age              0.028308      -0.030680  -0.011721        0.085472   \n",
       "Tenure          -0.007911       0.011979   0.027232       -0.032178   \n",
       "Balance          1.000000      -0.304180  -0.014858       -0.010084   \n",
       "NumOfProducts   -0.304180       1.000000   0.003183        0.009612   \n",
       "HasCrCard       -0.014858       0.003183   1.000000       -0.011866   \n",
       "IsActiveMember  -0.010084       0.009612  -0.011866        1.000000   \n",
       "EstimatedSalary  0.012797       0.014204  -0.009933       -0.011421   \n",
       "Exited           0.118533      -0.047820  -0.007138       -0.156128   \n",
       "\n",
       "                 EstimatedSalary    Exited  \n",
       "RowNumber              -0.005988 -0.016571  \n",
       "CustomerId              0.015271 -0.006248  \n",
       "CreditScore            -0.001384 -0.027094  \n",
       "Age                    -0.007201  0.285323  \n",
       "Tenure                  0.010520 -0.016761  \n",
       "Balance                 0.012797  0.118533  \n",
       "NumOfProducts           0.014204 -0.047820  \n",
       "HasCrCard              -0.009933 -0.007138  \n",
       "IsActiveMember         -0.011421 -0.156128  \n",
       "EstimatedSalary         1.000000  0.012097  \n",
       "Exited                  0.012097  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for correlations \n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column names to lowercase with underscores\n",
    "df.columns = df.columns.str.lower()\n",
    "df.rename(columns={'rownumber': 'row_number', 'customerid': 'customer_id', 'creditscore': 'credit_score','numofproducts': 'num_of_products', 'hascrcard': 'has_cr_card', 'isactivemember': 'is_active_member', 'estimatedsalary': 'estimated_salary' }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_number            0\n",
       "customer_id           0\n",
       "surname               0\n",
       "credit_score          0\n",
       "geography             0\n",
       "gender                0\n",
       "age                   0\n",
       "tenure              909\n",
       "balance               0\n",
       "num_of_products       0\n",
       "has_cr_card           0\n",
       "is_active_member      0\n",
       "estimated_salary      0\n",
       "exited                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: geography, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the different values of geography \n",
    "df.geography.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: tenure, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the different vales of tenure\n",
    "df.tenure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.997690023099769\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# mean and median tenure\n",
    "print(df.tenure.mean())\n",
    "print(df.tenure.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing tenure values with median\n",
    "df.tenure.fillna(df.tenure.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# looking for duplicates, hidden duplicates\n",
    "print(df.duplicated().sum())\n",
    "print(df.customer_id.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for hidden duplicates\n",
    "df.customer_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring two values for gender\n",
    "df.gender.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# ensuring these features have two values\n",
    "print(df.has_cr_card.nunique())\n",
    "print(df.is_active_member.nunique())\n",
    "print(df.exited.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all missing rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_number          0\n",
       "customer_id         0\n",
       "surname             0\n",
       "credit_score        0\n",
       "geography           0\n",
       "gender              0\n",
       "age                 0\n",
       "tenure              0\n",
       "balance             0\n",
       "num_of_products     0\n",
       "has_cr_card         0\n",
       "is_active_member    0\n",
       "estimated_salary    0\n",
       "exited              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models cannot work with missing or duplicate values, therefore we had to clean the data. We filled the missing tenure values, with the median of the column. The mean and median values were the same, so we went with the median, because it is an integer. The number of missing tenure values was roughly 9% of the data, which would have been too much to drop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the balance of genders\n",
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target is unbalanced\n",
    "df.exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of geography options\n",
    "df.geography.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing categorical columns to labels\n",
    "encoder = OrdinalEncoder()\n",
    "df_ordinal = pd.DataFrame(encoder.fit_transform(df[['surname', 'geography', 'gender']]), columns=['surname', 'geography', 'gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ordinal columns back into df\n",
    "df = df.merge(df_ordinal, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the left duplicate columns and rename the right columns\n",
    "df = df.drop(['surname_x', 'geography_x', 'gender_x'], axis=1)\n",
    "df.rename(columns={'surname_y': 'surname', 'geography_y': 'geography', 'gender_y': 'gender'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the target values\n",
    "df.exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5014\n",
       "1.0    2509\n",
       "2.0    2477\n",
       "Name: geography, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geography: 0 - France, 1 - Germany, 2 - Spain\n",
    "df.geography.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models cannot work with categorical features, therefore we had to label the features with numbers. Gender was converted to labels, with 0 - Female and 1 - Male. Geography was also converted to labels: 0 - France, 1 - Germany, 2 - Spain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target and Features\n",
    "target = df['exited']\n",
    "features = df.drop(['exited', 'row_number', 'customer_id', 'surname'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not believe row number, customer id, and surname are relevant features for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into 3: train, test, valid\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split( \n",
    "    features, target, test_size=0.2, random_state=19) # split 20% of data to make validation set\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=19) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n",
      "(6000,)\n",
      "(2000, 10)\n",
      "(2000,)\n",
      "(2000, 10)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Visual of the split data\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['credit_score', 'age', 'tenure', 'balance', 'num_of_products',\n",
       "       'has_cr_card', 'is_active_member', 'estimated_salary', 'geography',\n",
       "       'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names\n",
    "features_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using these numeric columns\n",
    "numeric = ['credit_score', 'age', 'tenure', 'balance', 'num_of_products','estimated_salary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not believe row number, customer id, and surname are relevant features for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Scaling the features\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "\n",
    "print(features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>0.703732</td>\n",
       "      <td>1.432882</td>\n",
       "      <td>0.713391</td>\n",
       "      <td>-1.217433</td>\n",
       "      <td>0.790787</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>2.046232</td>\n",
       "      <td>-1.811595</td>\n",
       "      <td>0.713391</td>\n",
       "      <td>-1.217433</td>\n",
       "      <td>0.790787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.183483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>0.047853</td>\n",
       "      <td>-1.143614</td>\n",
       "      <td>1.436178</td>\n",
       "      <td>-1.217433</td>\n",
       "      <td>0.790787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1.882263</td>\n",
       "      <td>0.955753</td>\n",
       "      <td>1.074784</td>\n",
       "      <td>1.346823</td>\n",
       "      <td>0.790787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.129838</td>\n",
       "      <td>0.669475</td>\n",
       "      <td>-0.732183</td>\n",
       "      <td>-1.217433</td>\n",
       "      <td>0.790787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.330867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>0.365544</td>\n",
       "      <td>-1.620743</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>-1.217433</td>\n",
       "      <td>0.790787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.030824</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>0.181079</td>\n",
       "      <td>0.669475</td>\n",
       "      <td>0.713391</td>\n",
       "      <td>1.366045</td>\n",
       "      <td>-0.920256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.274958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1.820774</td>\n",
       "      <td>-1.334466</td>\n",
       "      <td>0.713391</td>\n",
       "      <td>1.087362</td>\n",
       "      <td>-0.920256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>-1.745563</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.724523</td>\n",
       "      <td>-0.920256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.296458</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8307</th>\n",
       "      <td>-0.331326</td>\n",
       "      <td>-0.857337</td>\n",
       "      <td>-0.732183</td>\n",
       "      <td>0.919591</td>\n",
       "      <td>-0.920256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.181434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score       age    tenure   balance  num_of_products  \\\n",
       "7143      0.703732  1.432882  0.713391 -1.217433         0.790787   \n",
       "1730      2.046232 -1.811595  0.713391 -1.217433         0.790787   \n",
       "5253      0.047853 -1.143614  1.436178 -1.217433         0.790787   \n",
       "1601      1.882263  0.955753  1.074784  1.346823         0.790787   \n",
       "1034      0.129838  0.669475 -0.732183 -1.217433         0.790787   \n",
       "...            ...       ...       ...       ...              ...   \n",
       "1702      0.365544 -1.620743 -0.009396 -1.217433         0.790787   \n",
       "4201      0.181079  0.669475  0.713391  1.366045        -0.920256   \n",
       "4976      1.820774 -1.334466  0.713391  1.087362        -0.920256   \n",
       "9771     -1.745563  0.001495 -0.009396  0.724523        -0.920256   \n",
       "8307     -0.331326 -0.857337 -0.732183  0.919591        -0.920256   \n",
       "\n",
       "      has_cr_card  is_active_member  estimated_salary  geography  gender  \n",
       "7143            1                 1          0.442364        0.0     0.0  \n",
       "1730            1                 0         -1.183483        0.0     1.0  \n",
       "5253            0                 0          0.146972        2.0     0.0  \n",
       "1601            1                 0          0.515762        0.0     0.0  \n",
       "1034            0                 1          1.330867        0.0     1.0  \n",
       "...           ...               ...               ...        ...     ...  \n",
       "1702            1                 0          1.030824        2.0     1.0  \n",
       "4201            1                 1          1.274958        1.0     0.0  \n",
       "4976            1                 0          0.296202        1.0     0.0  \n",
       "9771            1                 1         -0.296458        2.0     1.0  \n",
       "8307            1                 1         -1.181434        0.0     1.0  \n",
       "\n",
       "[6000 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visual of the features\n",
    "features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scaled the data to account for feature weight imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target values before upsampling\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to upsample the features and target\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1]\n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "    \n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=19\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9666, 10)\n",
      "(9666,)\n"
     ]
    }
   ],
   "source": [
    "# Results of the upsampling, \n",
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4888\n",
       "0    4778\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at upsampled target counts\n",
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upsampled the data to balance out the churn target in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth: 2 ,  F1 of the best model on the validation set: 0.5122302158273381\n",
      "AUC-ROC score: 0.6598716710278545\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with loop for depth\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "for depth in range(1,20):\n",
    "    model_0 = DecisionTreeClassifier(random_state=19, max_depth=depth)\n",
    "    model_0.fit(features_train, target_train) # using unbalanced data for comparison\n",
    "    predictions_valid0 = model_0.predict(features_valid)\n",
    "    result0 = f1_score(target_valid, predictions_valid0) \n",
    "    if result0 > best_result:\n",
    "        best_model = model_0\n",
    "        best_result = result0\n",
    "        best_depth = depth  \n",
    "\n",
    "        \n",
    "print(\"Best Depth:\", best_depth, \",\"   \"  F1 of the best model on the validation set:\", best_result)\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid0 = model_0.predict_proba(features_valid)\n",
    "probabilities_one_valid0 = probabilities_valid0[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid0)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth: 6 ,  F1 of the best model on the validation set: 0.5752636625119847\n",
      "AUC-ROC score: 0.6804484788828838\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with loop for depth\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "for depth in range(1,20):\n",
    "    model = DecisionTreeClassifier(random_state=19, max_depth=depth)\n",
    "    model.fit(features_upsampled, target_upsampled) # using balanced, upsampled data\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result = f1_score(target_valid, predictions_valid) \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth  \n",
    "\n",
    "        \n",
    "print(\"Best Depth:\", best_depth, \",\"   \"  F1 of the best model on the validation set:\", best_result)\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are different due to the differences in the data used to train the model. The unbalanced data has more target values that are 0, thereby creating bias in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the logistic regression model on the validation set: 0.25621414913957935\n",
      "AUC-ROC score: 0.7691851507666725\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, no class weights\n",
    "model_002 = LogisticRegression(random_state=19, solver='saga', multi_class='multinomial')  \n",
    "model_002.fit(features_train, target_train)  # using unbalanced data for comparison\n",
    "predictions002_valid = model_002.predict(features_valid)\n",
    "f1_valid_002 = f1_score(target_valid, predictions002_valid)  \n",
    "\n",
    "print(\n",
    "    \"F1 score of the logistic regression model on the validation set:\",\n",
    "    f1_valid_002\n",
    ")\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid002 = model_002.predict_proba(features_valid)\n",
    "probabilities_one_valid002 = probabilities_valid002[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid002)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the logistic regression model on the validation set: 0.49613733905579394\n",
      "AUC-ROC score: 0.7746936978797291\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, balanced \n",
    "model_02 = LogisticRegression(random_state=19, solver='saga', class_weight='balanced', multi_class='multinomial')  \n",
    "model_02.fit(features_train, target_train)  # using balanced data for comparison\n",
    "predictions02_valid = model_02.predict(features_valid)\n",
    "f1_valid_02 = f1_score(target_valid, predictions02_valid)  \n",
    "\n",
    "print(\n",
    "    \"F1 score of the logistic regression model on the validation set:\",\n",
    "    f1_valid_02\n",
    ")\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid02 = model_02.predict_proba(features_valid)\n",
    "probabilities_one_valid02 = probabilities_valid02[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid02)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the logistic regression model on the validation set: 0.4923857868020305\n",
      "AUC-ROC score: 0.7747747059255092\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, not balanced, upsampled\n",
    "model20 = LogisticRegression(random_state=19, solver='saga', multi_class='multinomial')  \n",
    "model20.fit(features_upsampled, target_upsampled)  #  upsampled data\n",
    "predictions20_valid = model20.predict(features_valid)\n",
    "f1_valid20 = f1_score(target_valid, predictions20_valid)  \n",
    "\n",
    "print(\n",
    "    \"F1 score of the logistic regression model on the validation set:\",\n",
    "    f1_valid20\n",
    ")\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid20 = model20.predict_proba(features_valid)\n",
    "probabilities_one_valid20 = probabilities_valid20[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid20)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the logistic regression model on the validation set: 0.4965635738831615\n",
      "AUC-ROC score: 0.7747074539629748\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "model2 = LogisticRegression(random_state=19, solver='saga', class_weight='balanced', multi_class='multinomial')  \n",
    "model2.fit(features_upsampled, target_upsampled)  # using balanced, upsampled data\n",
    "predictions2_valid = model2.predict(features_valid)\n",
    "f1_valid2 = f1_score(target_valid, predictions2_valid)  \n",
    "\n",
    "print(\n",
    "    \"F1 score of the logistic regression model on the validation set:\",\n",
    "    f1_valid2\n",
    ")\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid2 = model2.predict_proba(features_valid)\n",
    "probabilities_one_valid2 = probabilities_valid2[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid2)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are improved with balancing and upsampling. The F1 score increases drastically with class weight balancing, and a little more with upsampling. Therefore, balanced weight classes are directly proportional to higher F1 scores in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, unbalanced, not upsampled (2 min run)\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(500, 800, 50):\n",
    "    for depth in range (700, 1001, 100):\n",
    "        model_003 = RandomForestClassifier(random_state=19, n_estimators=est, max_depth=depth)\n",
    "        model_003.fit(features_train, target_train) # using unbalanced data for comparison\n",
    "        predictions_valid_003 = model_003.predict(features_valid) \n",
    "        result_003 = f1_score(target_valid, predictions_valid_003) \n",
    "        if result_003 > best_result:\n",
    "            best_model = model_003\n",
    "            best_result = result_003\n",
    "            best_est = est\n",
    "            best_depth1 = depth\n",
    "\n",
    "print(\"F1 of the best model on the validation set:\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)\n",
    "\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid003 = model_003.predict_proba(features_valid)\n",
    "probabilities_one_valid003 = probabilities_valid003[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid003)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, balanced, not upsampled (2 min run)\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(500, 800, 50):\n",
    "    for depth in range (700, 1001, 100):\n",
    "        model_03 = RandomForestClassifier(random_state=19, class_weight='balanced', n_estimators=est, max_depth=depth)\n",
    "        model_03.fit(features_train, target_train) # using unbalanced data for comparison\n",
    "        predictions_valid_03 = model_03.predict(features_valid) \n",
    "        result_03 = f1_score(target_valid, predictions_valid_03) \n",
    "        if result_03 > best_result:\n",
    "            best_model = model_03\n",
    "            best_result = result_03\n",
    "            best_est = est\n",
    "            best_depth1 = depth\n",
    "\n",
    "print(\"F1 of the best model on the validation set:\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)\n",
    "\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid03 = model_03.predict_proba(features_valid)\n",
    "probabilities_one_valid03 = probabilities_valid03[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid03)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, not balanced, upsampled (2 min run)\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(200, 400, 20):\n",
    "    for depth in range (900, 1001, 50):\n",
    "        model3 = RandomForestClassifier(random_state=19, n_estimators=est, max_depth=depth)\n",
    "        model3.fit(features_upsampled, target_upsampled) # using balanced, upsampled data\n",
    "        predictions_valid3 = model3.predict(features_valid) \n",
    "        result3 = f1_score(target_valid, predictions_valid3) \n",
    "        if result3 > best_result:\n",
    "            best_model = model3\n",
    "            best_result = result3\n",
    "            best_est = est\n",
    "            best_depth1 = depth\n",
    "\n",
    "print(\"F1 of the best model on the validation set:\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid3 = model3.predict_proba(features_valid)\n",
    "probabilities_one_valid3 = probabilities_valid3[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid3)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, balanced, upsampled (2 min run)\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(200, 400, 20):\n",
    "    for depth in range (900, 1001, 50):\n",
    "        model30 = RandomForestClassifier(random_state=19, class_weight='balanced', n_estimators=est, max_depth=depth)\n",
    "        model30.fit(features_upsampled, target_upsampled) # using balanced, upsampled data\n",
    "        predictions_valid30 = model30.predict(features_valid) \n",
    "        result30 = f1_score(target_valid, predictions_valid30) \n",
    "        if result3 > best_result:\n",
    "            best_model = model30\n",
    "            best_result = result30\n",
    "            best_est = est\n",
    "            best_depth1 = depth\n",
    "\n",
    "print(\"F1 of the best model on the validation set:\", best_result, \"n_estimators:\", best_est, \"best_depth:\", depth)\n",
    "\n",
    "# AUC-ROC score \n",
    "probabilities_valid30 = model30.predict_proba(features_valid)\n",
    "probabilities_one_valid30 = probabilities_valid30[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid30)\n",
    "\n",
    "print('AUC-ROC score:', auc_roc)\n",
    "\n",
    "# final_model = RandomForestClassifier(random_state=19, n_estimators=320, max_depth=10000) \n",
    "# final_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are slightly better using the upsampled data. This model has the best F1 score, therefore we will use it for our final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model F1 score\n",
    "final_model = RandomForestClassifier(random_state=19, n_estimators=360, max_depth=1000) \n",
    "final_model.fit(features_upsampled, target_upsampled)\n",
    "final_prediction = final_model.predict(features_test)\n",
    "print(f1_score(final_prediction, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model uses 360 estimators and a max depth of 1,000. The F1 score meets our threshold of 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC-ROC score \n",
    "probabilities_test = final_model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual of AUC ROC\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "roc_data = {'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds}\n",
    "fig = px.line(roc_data, x='fpr', y='tpr', labels={'x':'False Positive Rate', 'y': 'True Positive Rate'}, \n",
    "              title=f'AUC ROC Curve (AUC={auc_roc:.3f})')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under the curve is greater than 0.50, which would be the value of a random model. The AUC-ROC is greater than a random model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to make a model that could predict whether a Beta Bank customer would churn. Using the key numeric features, and a few categorical features, we were able to train our model to achieve an F1 score of 0.594 on our test set. This F1 score is above the metric of a random model, which would have an F1 score of 0.5.  Looking at other metrics, we see our model is relatively accurate, at 0.851 with the test data. Based on the results of the classification report, we had greater precision and recall predicting when a customer would not churn. The model was fairly precise in predicting churn, and weak when it came to recalling churn. This means the model was not good at predicting most of the customers that would churn. Since F1 is a measure of precision and accuracy, our F1 score appears low. However, we achieved our 0.59 target with our test set. Furthermore, our AUC-ROC metric determines how much our model differs from a random model with an AUC-ROC of 0.50. An AUC-ROC score of 0.848 means our model is better at predicting churn than chance. Overall, Beta Bank can use this model to predict which customers will not churn. From there, they can determine the features that may contribute to a customer staying with them, in order to retain much more customers. Alternatively, this model can predict a decent portion of customers that would churn. We suggest more data is collected, with more features that could contribute to customers churning. Another way of improving the model would be to be to see if the max depth approaches a limit. Data without missing tenures would also aid in improving the results, as well as more balanced data on churned customers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4f2b0cfe12c109b58467a02dc33230d9e6228c23b43020d2941c37e2a7dfdd3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
